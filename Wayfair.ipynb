{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this cell, I am loading all the libraries for creation of this Prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from numpy import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import *\n",
    "\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I am loading the training dataset which is already labelled and I am ignoring the unnamed row which doesn't count as a feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cuid  convert_30  revenue_30     roll_up currentstatus companytypegroup  \\\n",
      "0    20           0         0.0  Onboarding        Active         Business   \n",
      "1    57           0         0.0  Onboarding        Active         Business   \n",
      "2   163           0         0.0  Onboarding        Active         Business   \n",
      "3   167           0         0.0  Onboarding      Enrolled         Business   \n",
      "4   168           0         0.0  Onboarding      Enrolled         Business   \n",
      "\n",
      "  team            customersource accrole num_employees  ...  \\\n",
      "0   US      External Application    None        50plus  ...   \n",
      "1   US      Internal Application    None          2to5  ...   \n",
      "2   US      Internal Application    None             1  ...   \n",
      "3   US  Internal Customer Scrape    None        50plus  ...   \n",
      "4   US                   Gateway    None         6to10  ...   \n",
      "\n",
      "  percemailopenedyearsixty percemailclickedone percemailclickedthreeone  \\\n",
      "0                 0.000000                 0.0                      0.0   \n",
      "1                 0.020000                 0.0                      0.0   \n",
      "2                 0.106195                 0.0                      0.0   \n",
      "3                 0.100000                 0.0                      0.0   \n",
      "4                 0.072072                 0.0                      0.0   \n",
      "\n",
      "   percemailclickedseventhree  percemailclickedthirtyseven  \\\n",
      "0                         0.0                     0.190476   \n",
      "1                         0.0                     0.040000   \n",
      "2                         0.0                     0.000000   \n",
      "3                         0.0                     0.000000   \n",
      "4                         0.0                     0.009524   \n",
      "\n",
      "   percemailclickedsixtythirty  percemailclickedyearsixty  \\\n",
      "0                     0.000000                   0.000000   \n",
      "1                     0.000000                   0.020000   \n",
      "2                     0.000000                   0.001770   \n",
      "3                     0.000000                   0.100000   \n",
      "4                     0.016807                   0.003465   \n",
      "\n",
      "   currentapplicability  numemaillist  dayssinceenrollment  \n",
      "0              3.000000           1.0                   17  \n",
      "1              3.000000           1.0                   70  \n",
      "2             13.000000           1.0                   27  \n",
      "3                   NaN           NaN                   25  \n",
      "4              8.333333           3.0                   33  \n",
      "\n",
      "[5 rows x 183 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"df_training_scholarjet.csv\")\n",
    "df = df.loc[:, ~df.columns.str.contains('Unnamed')]\n",
    "print (df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this prediction model, \"Convert_30\" and \"revenue_30\" are the labels to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = np.asarray(df.convert_30)\n",
    "labels2 = np.asarray(df.revenue_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I am encoding the labels using the label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(labels1)\n",
    "labels1 = le.transform(labels1)\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "le2.fit(labels2)\n",
    "labels2 = le2.transform(labels2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell, I am dropping the following columns because they are the labels to be predicted and they doesn't count as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df.drop(['revenue_30', 'cuid', 'convert_30'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell, I am extracting features from the training dataset and fitting the features into an array using the \"DictVectorizer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.     0.     0.   ...   0.     0.    59.99]\n",
      " [  1.     0.     0.   ...   0.    78.   126.48]\n",
      " [  1.     0.     0.   ...   0.     0.   237.98]\n",
      " ...\n",
      " [  0.     0.     0.   ...   0.   119.     0.  ]\n",
      " [  1.     0.     0.   ...   0.     0.     0.  ]\n",
      " [  1.     0.     0.   ...   0.     0.   409.99]]\n"
     ]
    }
   ],
   "source": [
    "df_features = df_selected.to_dict(orient='records')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "features = vec.fit_transform(df_features).toarray()\n",
    "where_are_NaNs = isnan(features)\n",
    "features[where_are_NaNs] = 0\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this particular cell, I am splitting the training and testing dataset into 90% and 10% composition respectively to find the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train1, features_test1, labels_train1, labels_test1 = train_test_split(\n",
    "    features, labels1, \n",
    "    test_size=0.10, random_state=42)\n",
    "\n",
    "features_train2, features_test2, labels_train2, labels_test2 = train_test_split(\n",
    "    features, labels2, \n",
    "    test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Training the model using Random Forest Classifier.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karti\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8944187699964451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf1 = RandomForestClassifier()\n",
    "clf1.fit(features_train1, labels_train1)\n",
    "\n",
    "acc_test = clf1.score(features_test1, labels_test1)\n",
    "print (\"Test Accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model using SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8944187699964451\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf2 = svm.SVC(gamma='scale', C=1.0, kernel='rbf')\n",
    "clf2.fit(features_train1, labels_train1)\n",
    "\n",
    "acc_test = clf2.score(features_test1, labels_test1)\n",
    "print (\"Test Accuracy:\", acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the testing dataset and eliminating the unnamed columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     cuid     roll_up currentstatus companytypegroup team  \\\n",
      "0   16838  Onboarding      Enrolled         Business   US   \n",
      "1  532175  Onboarding      Enrolled         Business   US   \n",
      "2  532176  Onboarding      Enrolled         Business   US   \n",
      "3  532187  Onboarding      Enrolled         Business   US   \n",
      "4   16938  Onboarding      Enrolled            Trade   US   \n",
      "\n",
      "             customersource  accrole num_employees num_purchases_year  \\\n",
      "0      Internal Application     None             1               1to2   \n",
      "1             Search - Paid     None         6to10               None   \n",
      "2      Internal Application     None        11to50               3to5   \n",
      "3      Internal Application  Primary          None               None   \n",
      "4  Internal Customer Scrape  Primary          None               None   \n",
      "\n",
      "  cost_purchases_year  ... percemailopenedyearsixty  percemailclickedone  \\\n",
      "0           lessthan1  ...                 0.025806                  0.0   \n",
      "1                None  ...                 0.000000                  0.0   \n",
      "2                1to5  ...                 0.036190                  0.0   \n",
      "3                None  ...                 1.000000                  0.0   \n",
      "4                None  ...                 0.049383                  0.5   \n",
      "\n",
      "   percemailclickedthreeone  percemailclickedseventhree  \\\n",
      "0                       0.0                         0.0   \n",
      "1                       0.0                         0.0   \n",
      "2                       0.0                         0.0   \n",
      "3                       0.0                         0.5   \n",
      "4                       0.0                         0.0   \n",
      "\n",
      "   percemailclickedthirtyseven  percemailclickedsixtythirty  \\\n",
      "0                     0.021739                     0.012821   \n",
      "1                     0.000000                     0.000000   \n",
      "2                     0.000000                     0.000000   \n",
      "3                     0.272727                     0.250000   \n",
      "4                     0.000000                     0.043478   \n",
      "\n",
      "   percemailclickedyearsixty  currentapplicability  numemaillist  \\\n",
      "0                   0.032258                   5.0           2.0   \n",
      "1                   0.000000                   NaN           NaN   \n",
      "2                   0.015238                   8.0           4.0   \n",
      "3                   0.000000                   NaN           NaN   \n",
      "4                   0.016461                   5.0           2.0   \n",
      "\n",
      "   dayssinceenrollment  \n",
      "0                   86  \n",
      "1                    3  \n",
      "2                   13  \n",
      "3                   10  \n",
      "4                   42  \n",
      "\n",
      "[5 rows x 181 columns]\n",
      "[ 16838 532175 532176 ... 437287 532142 532158]\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"df_holdout_scholarjet.csv\")\n",
    "df2 = df2.loc[:, ~df2.columns.str.contains('Unnamed')]\n",
    "print (df2.head())\n",
    "\n",
    "cuid = df2['cuid'].values\n",
    "print(cuid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly creating the features for the testing dataset and predicting the \"Convert_30\" label for the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.  0.5 0.3 ... 0.  0.  0. ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.0: 15918,\n",
       " 0.1: 6870,\n",
       " 0.2: 3392,\n",
       " 0.3: 1854,\n",
       " 0.4: 1120,\n",
       " 0.5: 570,\n",
       " 0.6: 388,\n",
       " 0.7: 165,\n",
       " 0.8: 72,\n",
       " 0.9: 23,\n",
       " 1.0: 3}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = df2.drop(['cuid'], axis=1)\n",
    "df_features = df_selected.to_dict(orient='records')\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "vec = DictVectorizer()\n",
    "features = vec.fit_transform(df_features).toarray()\n",
    "where_are_NaNs = isnan(features)\n",
    "features[where_are_NaNs] = 0\n",
    "\n",
    "\n",
    "output = clf1.predict_proba(features)\n",
    "pred = output[:,1]\n",
    "print(pred)\n",
    "    \n",
    "\n",
    "unique, counts = np.unique(pred, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a revenue prediction model by using Decision tree classifier with a depth of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8563810878066122\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import graphviz\n",
    "\n",
    "t = tree.DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
    "t = t.fit(features_train2, labels_train2)\n",
    "accuracy = t.score(features_test2, labels_test2)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of \"revenue_30\" label for the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 29000,\n",
       " 1: 5,\n",
       " 2: 2,\n",
       " 4: 1,\n",
       " 5: 7,\n",
       " 7: 10,\n",
       " 8: 1,\n",
       " 9: 3,\n",
       " 16: 2,\n",
       " 17: 4,\n",
       " 23: 5,\n",
       " 24: 7,\n",
       " 25: 10,\n",
       " 27: 4,\n",
       " 30: 5,\n",
       " 32: 7,\n",
       " 33: 1,\n",
       " 37: 3,\n",
       " 38: 1,\n",
       " 39: 3,\n",
       " 44: 4,\n",
       " 45: 4,\n",
       " 46: 4,\n",
       " 52: 7,\n",
       " 53: 14,\n",
       " 57: 1,\n",
       " 62: 1,\n",
       " 64: 10,\n",
       " 66: 4,\n",
       " 67: 5,\n",
       " 68: 2,\n",
       " 69: 8,\n",
       " 72: 5,\n",
       " 76: 5,\n",
       " 78: 4,\n",
       " 81: 4,\n",
       " 85: 1,\n",
       " 93: 3,\n",
       " 96: 6,\n",
       " 103: 5,\n",
       " 107: 3,\n",
       " 109: 9,\n",
       " 113: 8,\n",
       " 115: 2,\n",
       " 123: 3,\n",
       " 125: 1,\n",
       " 129: 6,\n",
       " 130: 3,\n",
       " 133: 4,\n",
       " 135: 1,\n",
       " 138: 3,\n",
       " 139: 15,\n",
       " 141: 3,\n",
       " 144: 4,\n",
       " 146: 6,\n",
       " 148: 5,\n",
       " 149: 1,\n",
       " 152: 4,\n",
       " 153: 1,\n",
       " 160: 4,\n",
       " 161: 6,\n",
       " 167: 5,\n",
       " 174: 9,\n",
       " 175: 3,\n",
       " 180: 3,\n",
       " 182: 7,\n",
       " 183: 4,\n",
       " 185: 1,\n",
       " 193: 3,\n",
       " 195: 7,\n",
       " 200: 6,\n",
       " 202: 6,\n",
       " 203: 3,\n",
       " 204: 5,\n",
       " 210: 2,\n",
       " 213: 2,\n",
       " 215: 4,\n",
       " 217: 5,\n",
       " 221: 10,\n",
       " 227: 7,\n",
       " 229: 4,\n",
       " 232: 1,\n",
       " 233: 1,\n",
       " 236: 2,\n",
       " 237: 3,\n",
       " 240: 7,\n",
       " 241: 2,\n",
       " 244: 3,\n",
       " 246: 3,\n",
       " 248: 2,\n",
       " 250: 4,\n",
       " 252: 2,\n",
       " 254: 1,\n",
       " 255: 5,\n",
       " 256: 5,\n",
       " 258: 14,\n",
       " 259: 1,\n",
       " 260: 1,\n",
       " 261: 15,\n",
       " 262: 3,\n",
       " 265: 6,\n",
       " 266: 5,\n",
       " 268: 10,\n",
       " 271: 9,\n",
       " 275: 4,\n",
       " 290: 4,\n",
       " 301: 1,\n",
       " 302: 2,\n",
       " 303: 1,\n",
       " 312: 4,\n",
       " 316: 5,\n",
       " 323: 9,\n",
       " 325: 10,\n",
       " 326: 2,\n",
       " 332: 1,\n",
       " 334: 3,\n",
       " 335: 11,\n",
       " 341: 1,\n",
       " 342: 17,\n",
       " 343: 2,\n",
       " 344: 1,\n",
       " 347: 2,\n",
       " 352: 3,\n",
       " 354: 3,\n",
       " 363: 2,\n",
       " 367: 3,\n",
       " 369: 2,\n",
       " 376: 7,\n",
       " 377: 2,\n",
       " 379: 9,\n",
       " 382: 4,\n",
       " 383: 3,\n",
       " 385: 4,\n",
       " 386: 1,\n",
       " 394: 2,\n",
       " 395: 3,\n",
       " 400: 1,\n",
       " 401: 9,\n",
       " 403: 2,\n",
       " 405: 5,\n",
       " 407: 11,\n",
       " 424: 2,\n",
       " 425: 5,\n",
       " 431: 1,\n",
       " 433: 12,\n",
       " 434: 4,\n",
       " 435: 4,\n",
       " 439: 6,\n",
       " 442: 2,\n",
       " 443: 1,\n",
       " 451: 1,\n",
       " 452: 6,\n",
       " 455: 3,\n",
       " 467: 2,\n",
       " 478: 8,\n",
       " 482: 1,\n",
       " 484: 3,\n",
       " 485: 2,\n",
       " 486: 2,\n",
       " 494: 3,\n",
       " 497: 2,\n",
       " 499: 4,\n",
       " 503: 2,\n",
       " 504: 6,\n",
       " 510: 6,\n",
       " 514: 1,\n",
       " 515: 3,\n",
       " 520: 5,\n",
       " 521: 1,\n",
       " 527: 4,\n",
       " 528: 3,\n",
       " 530: 3,\n",
       " 532: 3,\n",
       " 534: 3,\n",
       " 537: 1,\n",
       " 538: 1,\n",
       " 543: 3,\n",
       " 550: 2,\n",
       " 557: 2,\n",
       " 562: 4,\n",
       " 563: 3,\n",
       " 567: 15,\n",
       " 569: 4,\n",
       " 570: 7,\n",
       " 577: 7,\n",
       " 581: 4,\n",
       " 582: 2,\n",
       " 585: 2,\n",
       " 587: 1,\n",
       " 589: 3,\n",
       " 591: 9,\n",
       " 595: 4,\n",
       " 603: 3,\n",
       " 607: 5,\n",
       " 618: 4,\n",
       " 625: 3,\n",
       " 631: 1,\n",
       " 632: 3,\n",
       " 635: 6,\n",
       " 637: 4,\n",
       " 661: 3,\n",
       " 669: 1,\n",
       " 671: 9,\n",
       " 679: 5,\n",
       " 684: 4,\n",
       " 685: 2,\n",
       " 691: 2,\n",
       " 703: 1,\n",
       " 709: 3,\n",
       " 713: 2,\n",
       " 714: 3,\n",
       " 715: 3,\n",
       " 719: 6,\n",
       " 725: 4,\n",
       " 726: 4,\n",
       " 738: 2,\n",
       " 742: 11,\n",
       " 746: 15,\n",
       " 748: 24,\n",
       " 749: 2,\n",
       " 752: 2,\n",
       " 758: 4,\n",
       " 761: 3,\n",
       " 770: 2,\n",
       " 778: 2,\n",
       " 797: 3,\n",
       " 799: 1,\n",
       " 804: 2,\n",
       " 808: 1,\n",
       " 814: 1,\n",
       " 819: 4,\n",
       " 838: 2,\n",
       " 843: 2,\n",
       " 849: 2,\n",
       " 853: 1,\n",
       " 862: 7,\n",
       " 871: 9,\n",
       " 873: 3,\n",
       " 876: 1,\n",
       " 886: 5,\n",
       " 889: 2,\n",
       " 895: 3,\n",
       " 896: 8,\n",
       " 902: 5,\n",
       " 906: 3,\n",
       " 912: 3,\n",
       " 924: 1,\n",
       " 926: 2,\n",
       " 931: 5,\n",
       " 940: 3,\n",
       " 941: 4,\n",
       " 945: 18,\n",
       " 953: 1,\n",
       " 965: 4,\n",
       " 988: 4,\n",
       " 1000: 1,\n",
       " 1002: 1,\n",
       " 1004: 2,\n",
       " 1009: 3,\n",
       " 1025: 1,\n",
       " 1064: 2,\n",
       " 1071: 2,\n",
       " 1082: 1,\n",
       " 1111: 1,\n",
       " 1114: 1,\n",
       " 1115: 3,\n",
       " 1136: 2,\n",
       " 1138: 4,\n",
       " 1139: 5,\n",
       " 1149: 1,\n",
       " 1152: 1,\n",
       " 1159: 1,\n",
       " 1161: 1,\n",
       " 1188: 1,\n",
       " 1197: 1,\n",
       " 1240: 3,\n",
       " 1243: 2,\n",
       " 1244: 1,\n",
       " 1245: 1,\n",
       " 1262: 1,\n",
       " 1266: 1,\n",
       " 1267: 1,\n",
       " 1272: 2,\n",
       " 1278: 5,\n",
       " 1291: 3,\n",
       " 1295: 1,\n",
       " 1311: 3,\n",
       " 1329: 7,\n",
       " 1330: 1,\n",
       " 1331: 6,\n",
       " 1332: 2,\n",
       " 1338: 10,\n",
       " 1345: 2,\n",
       " 1355: 1,\n",
       " 1365: 5,\n",
       " 1397: 3,\n",
       " 1428: 2,\n",
       " 1445: 16,\n",
       " 1459: 2,\n",
       " 1465: 2,\n",
       " 1470: 1,\n",
       " 1473: 1,\n",
       " 1485: 1,\n",
       " 1491: 3,\n",
       " 1525: 4,\n",
       " 1538: 1,\n",
       " 1546: 5,\n",
       " 1552: 1,\n",
       " 1555: 1,\n",
       " 1559: 9,\n",
       " 1578: 3,\n",
       " 1580: 12,\n",
       " 1583: 3,\n",
       " 1591: 3,\n",
       " 1592: 1,\n",
       " 1603: 2,\n",
       " 1607: 1,\n",
       " 1616: 2,\n",
       " 1632: 2,\n",
       " 1636: 2,\n",
       " 1681: 5,\n",
       " 1698: 2,\n",
       " 1716: 1,\n",
       " 1749: 4,\n",
       " 1751: 1,\n",
       " 1773: 3,\n",
       " 1779: 1,\n",
       " 1789: 5,\n",
       " 1809: 2,\n",
       " 1821: 5,\n",
       " 1846: 2,\n",
       " 1859: 6,\n",
       " 1884: 1,\n",
       " 1894: 3,\n",
       " 1923: 4,\n",
       " 1952: 3,\n",
       " 1956: 1,\n",
       " 1972: 6,\n",
       " 1985: 3,\n",
       " 1995: 2,\n",
       " 1997: 1,\n",
       " 2001: 4,\n",
       " 2027: 4,\n",
       " 2031: 3,\n",
       " 2056: 4,\n",
       " 2071: 2,\n",
       " 2089: 2,\n",
       " 2103: 2,\n",
       " 2106: 1,\n",
       " 2140: 2,\n",
       " 2141: 4,\n",
       " 2193: 1,\n",
       " 2194: 1,\n",
       " 2203: 3,\n",
       " 2235: 2,\n",
       " 2256: 2,\n",
       " 2313: 2,\n",
       " 2331: 2,\n",
       " 2358: 9,\n",
       " 2376: 3,\n",
       " 2465: 10,\n",
       " 2529: 2}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2 = t.predict(features)\n",
    "\n",
    "\n",
    "unique, counts = np.unique(pred2, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing all the predictions in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('predictions.csv', mode='w') as f:\n",
    "    mywriter = csv.writer(f, delimiter=',')\n",
    "    myrow = ['cuid']\n",
    "    row = ['convert_30']\n",
    "    myrow.extend(row)\n",
    "    row = ['revenue_30']\n",
    "    myrow.extend(row)\n",
    "    mywriter.writerow(myrow)\n",
    "    \n",
    "    for i in range(len(cuid)):\n",
    "        myrow = [cuid[i]]\n",
    "        row = [pred[i]]\n",
    "        myrow.extend(row)\n",
    "        row = [pred2[i]]\n",
    "        myrow.extend(row)\n",
    "        mywriter.writerow(myrow)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
